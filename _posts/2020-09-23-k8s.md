---
layout: post
title: K8s的历史、浅略技术分析及展望
image: /img/k8s.png
tag: [K8s, Centos]
---

语言边界就是世界的边界
—— 《逻辑哲学论》

## 一、K8s 的意义及由来

**Kubernates**，习惯上也称为 K8s。是一个开源系统，用于跨多个主机管理容器化的应用程序。 它提供了用于部署，维护和扩展应用程序的基本机制。Kubernetes 建立在 Google 十年半的经验之上，使用称为[Borg](https://research.google/pubs/pub43438/)(有兴趣可以了解一下)的系统大规模运行生产工作负载，并结合了社区中的最佳创意和实践。以上对 k8s 的描述我们都可以在 kubernates 的官方 github 项目 README 里找到相应的解释[https://github.com/kubernetes/kubernetes](https://github.com/kubernetes/kubernetes)。然而官方文档的解释更倾向于 Kubernetes 是一个可移植的，可扩展的开源平台，用于管理容器化的工作负载和服务，可促进声明式配置和自动化。 它拥有一个庞大且快速增长的生态系统。 而 Kubernetes 的服务，支持和工具广泛应用

### 历史插曲

在 Google 中 Kubernetes 的原始代号是 Project 7，是对《星际迷航》前博格角色["Seven of Nine"](https://en.wikipedia.org/wiki/Seven_of_Nine)的引用。Kubernetes 徽标上的七个辐条是对该代号的引用。 最初的 Borg 项目完全是用 C ++ 编写的，但是重写的 Kubernetes 系统是在 Go 中实现的。

---

**下面从以下几个方面对 k8s 展开论述**，首先声明，我对任何技术的分析尽量做到绝对的客观，但是个人的思考和见识不能除外，毕竟技术在某种意义上也是比较主观的。然而，对于那些主观的看法希望各位读者给予相应的宽容抑或相应的建议。笔者亦倍感欣慰、故在此深表感意。

## 二、技术优势

### 1.1 容器化技术的流行

我们来看看这些年来，应用在部署机制上的演变历程。这些年我们可以粗略的归纳为三个应用部署时代。传统部署时代，虚拟化部署时代，容器化部署时代。他们各自有各自的架构实现，如下图所示。

![应用部署发展历程](/img/deploy.png)

以及各自的优劣，如下图。

![应用部署各时代优劣](/img/deployAD.png)

那么容器化真正流行起来的因素有哪些呢，或者他有哪些真正能解决问题的点呢？如下图。

![容器化部署的优势](/img/containers.png)

说了这么多容器化部署的优点，那书归正传，请出今天的主角，K8s。为什么需要它，或者它能为我们做什么呢？

### 1.2 为什么需要 k8s，它能为我们做什么呢

首先容器是应用程序打包和运行的最好方式。在生产环境中，你需要管理这些容器，保证容器的稳定、不宕机的运行。那么你就需要一个管理容器的利器——k8s。

它能提供的服务有哪些呢？如下图。

![k8s提供的服务](/img/k8sservice.png)

顺便说下，k8s 类似于传统的 Pass 平台但和它却有相当大的差别。k8s 的运行是基于容器级别而非硬件级别，提供构建开发人员平台的基础，但保留了用户的选择和灵活性。比如，不限制支持的应用程序类型，不部署源代码，不提供程序级别的内置服务，中间件等，不指定日志记录，不提供采用任何全面管理的机器配置、维护、管理、或者自我修复。它不仅仅是编排系统，实际上它消除了编排的需要。编排的技术定义是执行定义的工作流程。比如，从 A 到 B 再到 C 的执行顺序。相反，k8s 包含一组独立的、可组合的控制过程。这些过程连续地将当前状态驱动到所提供的所需状态。无需关注从 A 到 C 的执行顺序，也不需要集中控制。（解释一下，K8s 容器应用之间的状态通信是通过注册来发现的，所以我们把每个容器来看的话，就没必要关注容器的启动顺序，这些服务的状态都会记录在注册机上，一旦识别服务状态可用自然会加入到集群中来，然而整个过程都是由 k8s 的 controller 来完成的）这使得系统功能更强大、健壮、弹性和可扩展性。
**好的，我们已经讲解了容器化部署历程以及典型的容器化管理工具——k8s 的意义和使用场景。那接下来，我们将进入本篇的重头戏——聊聊 k8s 的架构**

### 1.3 K8s 的基础架构

首先由一张图来引入 K8s 的架构，如下图所示。

![k8s提供的服务](/img/k8sarch.png)

接着我会细致的描述里面各个组件的意义和关系。

#### 1.3.1 k8s 的控制面

控制面是 k8s 集群的重要组成部分，在*控制面*里可以找到 kubernetes 控制集群的相关组件，还有一些集群的状态和配置的数据。这些核心的组件是保证集群稳定运行以及分配资源的重要利器。

- kube-apiserver

kube-apiserver，可以理解为控制面的暴露的前端接口，用于处理内部和外部请求。可以通过 REST 方式访问 API 或者使用 kubectl 来调用

- kube-scheduler

kube-scheduler, 顾名思义调度器。它会检查 pod 的资源需求以及集群的运行状态，它将 pod 分配到适当的计算节点进行调度。

- kube-controller-manager

可以理解为 kubernetes 的集群控制管理器。如果说，控制器负责实际运行集群，那么 k8s 的控制管理器则是将多个控制器功能合而为一。一个控制器查询调度程序，并确保正确数量的 Pod 正在运行。如果 pod 宕机，则另一个控制器会注意到并做出响应。控制器将服务连接到 Pod，因此请求将转发到健康的端点上。并且还有用于创建帐户和 API 访问令牌的控制器。

- etcd

etcd 是一个容错的、分布式的键值存储数据库。配置数据的有关集群状态的信息位于其中。有兴趣的可以在[github](https://github.com/etcd-io/etcd)或[官网](https://etcd.io/)上了解更多关于 etcd 的知识。

#### 1.3.2 k8s 的 node

- Nodes

Kubernetes 集群至少需要一个计算节点，但是通常会很多。Pod 在节点上被调度和编排。如果性能出现瓶颈可根据命令添加更多节点。节点是具有伸缩性的。

- Pods

Pod 是 K8s 对象模型中最小和最简单的运行单位。它代表一个应用程序的单个实例。每个 Pod 由一个容器或一系列紧密耦合的容器以及控制容器运行方式的选件组成。Pod 可以连接到持久性存储，以运行有状态的应用程序。

- Container runtime engine

容器运行时引擎。为了运行容器，每个计算节点都有一个容器运行时 引擎。比如[Docker](https://www.docker.com/)，比较常见。

- kubelet

每个计算节点都包含一个 kubelet，这是一个与控制面进行通信的 APP。kubelet 会执行一系列操作指令来控制容器，比如增加、减少节点的指令。

- kube-proxy

每一个计算节点还包含一个 kube-proxy。这是用于 k8s 网络服务的代理程序。kube-proxy 处理集群内部或外部的网络通信，依靠操作系统的数据包过滤层，转发流量本身。

#### 1.3.2 K8s 集群还需要什么

- Persistent storage

除了管理运行应用程序的容器外，K8s 还可以管理集群的应用程序数据。k8s 允许用户请求存储资源，而无需了解底层存储基础架构的详情。永久卷指定在集群内，而不是容器，因此可以超过容器的存活时间。

- Container registry

K8s 依赖的容器镜像存储在容器注册表中。注册表可以是自己的也可以是第三方的。

---

## 三、存在的不足

前面都在用大量的篇幅去描述 K8S，优异的一面。那它的不足之处呢？任何事物的出现都会伴随着优缺点。只有了解这些不足的地方我们才能知道有所改进的地方。一个新的技术固然会解决一些新的问题，但同样会引入其他的挑战。
下面我列出的一些缺陷，你可以用他们来判断自己是否真的需要使用 k8s。

- 复杂度

  [Kubernetes 自身的安装、配置、管理](https://kubernetes.io/docs/concepts/overview/components/)非常复杂。

- 在不知情的情况下，[过度分配或者分配不足的可用资源](https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/),会导致可怕的结果。

  1. Pods 无法启动
  2. 在高负载情况下，Pods 可能会崩溃

- [创建外部负载均衡器](https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/)的技术学习成本高，管理起来比较困难。尽量不要使用。

- 需要为每个组件创建健康检查端点

- [大规模运行 Kubernetes 需要集成和自动化](https://github.com/kelseyhightower/pipeline)

- [YAML 的学习成本高，复杂性高, 如果大量的 YAML 文件也是难于管理](https://www.arp242.net/yaml-config.html)

- 监控

  如果你想了解基础架构、K8S 和应用服务之间的关系时，Kubernetes 需要特殊的监控工具。

以上为被大部分开发和运维人员说诟病的缺陷。而正因为有了这些缺陷，我们才要去继续改进 K8S 的功能。这里必须强调一点，能在 K8S 上的部署的工程都是云原生的项目。但是很多应用并未采用云原生的规范来进行对项目的
架构设计。所以，并不是每一个项目都是云原生的项目。[云原生白皮书](https://jimmysong.io/guide-to-cloud-native-app/docs/)里介绍了，云原生应用的定义以及规范。

---

## 四、未来的规划
